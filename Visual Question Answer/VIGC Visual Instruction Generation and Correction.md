# VIGC: Visual Instruction Generation and Correction

## 简介

多模态大模型（MLLM）取得了非常大的进展，但是为视觉语言任务提供的高质量指令调优数据还是很脆弱。传统的方法，如模型LLaVA，只能通过GPT-4利用文本来生成数据，这样对图像细节的理解很少。因此应该用多模态大模型来生成数据，可是目前这些大模型会生成不充分的、错误的回答。因此本文提出VIGC模型，来辅助数据的生成。
