# Rethinking Few-shot Class-incremental Learning: Learning from Yourself

## 背景

尽管现存的深度神经网络（DNN）在各种真实场景的应用中取得巨大成就，他们仍在处理线性数据流时遭受着**灾难遗忘**。这个遗忘在近些年引起了很大的关注。

本文则关注于一个更加现实且有挑战性的问题：小样本类别增量学习（FSCIL）。它会在一个带有充足数据的基础任务上进行训练，并在新任务中根据仅有的样本进行增量学习。在Tao提出了FSCIL这个benchmark之后，一大批方法被提出来解决这个问题，包括基于元学习的方法、基于结构的方法、基于特征空间的方法等等。

目前流行的FSCIL的评估度量通常使用平均准确率（$aAcc$）和最后任务的平均准确率（$lAcc$）。然而，本文揭示出这两个评估度量会导致模型不注重新类的表现，从而导致FSCIL方法的持续学习能力被忽略。

## 新度量

本文提出了一个增补性的新度量，称为泛化平均准确率（$gAcc$），通过参数$\alpha$的引领就可以从不同的性能角度进行一个客观的评估。本文还将$\alpha$下AUC作为整体度量。在$gAcc$的引领下，本文释放了视觉transformer中间层特征的潜力，提升了新类表现。

## 模型构建

由于从中间层中提取信息不会偏向某一类，而是具有泛化性，因此本文想尝试改正最终特征，促进更加具有泛化性的基于transformer的FSCIL框架。

## 实验结果

在没有复杂网络设计和笨重训练过程的情况下，本文的方法在$aAcc$和$gAcc$指标上超过了目前现有的FSCIL方法。
