# Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task

## 背景

目前VQA系统经常在特定的数据集上训练，并且在使用中模型保持固定。但在现实，很难一次性就把VQA系统搭建好，因为用户的需求会持续性变化。VQA系统需要持续学习知识，无论是应用于新场景还是添加新功能。

在计算机视觉社区，有很多处理图像分类中持续学习（CL）的方法，模型需要按序处理不同的分类任务，每个人物的标签都不同。在这个任务下，模型会在视觉模态下持续提升识别这一种能力，并且主要学习每一类别的表示。而在VQA中，模型需要适应许多新的环境、学习许多新的能力。所以VQA任务中的CL，与图像分类任务不同，会在多种模态下持续学习新的能力，并且更关注于推理过程。因此，持续学习是搭建一个更好VQA系统的必要能力。

![Fig1](./fig/VQA%20continual%20learning.png)

最近，一个开创新的工作将VQA数据集分成wh-和yes/no两个问答集来学习这一课题（Greco et al）。但是，这种划分方法很难让我们了解持续学习的新场景和新功能。具体来说，对于图形领域，wh-和yes/no问题都是关于几何范围的。对于功能来说，两种类型的问题都是关于物体属性和属性的多跳推理的。“*这个正方体是什么颜色？*”和“*这个正方体是红色的吗？*”两个问题其实涉及到同样的功能，知识问的方式不一样。

## CLOVE

本文通过将目前现存的VQA数据集进行重组织，构建出CLOVE，一个为VQA上持续学习的benchmark，包含着场景增量、功能增量两种CL设定。

1. 场景增量：VQA模型需要适应于新的场景。本文设置了购物和餐饮环境、工作环境、家庭旅店环境、交通、运动休闲、户外六种场景。

2. 功能增量：VQA模型需要适应新功能。本文设置了物体识别、属性识别、关系推理、逻辑推理、知识推理和场景文本理解六种功能。

具体来说，本文定义了包含$N$个VQA任务的序列，既$\mathbf{T} = (T_1, T_2, \cdots, T_N)$。其中第$i$个任务$T_i$利用任务特定的数据集$D_i = \{\mathbf{d}_1^i, \cdots, \mathbf{d}_n^i, \cdots, \mathbf{d}_{\left | D_i \right |}^i\}$。其中，$\mathbf{d}_n^i$代表着一个图像、问题、回答三元组$\{\mathbf{v}_n^i, \mathbf{q}_n^i, \mathbf{a}_n^i\}$。图像和问题是VQA模型的输入，我们期望会输出标准答案。

### 场景设定

#### 图像分配

为了给每个任务分配图像，本文依靠sota场景分类模型来获得一个初始的划分。接下来，本文使用两个后处理策略来提升已选图片的质量：

1. 利用分类置信分数阈值过滤照片。
2. 限制图片中频繁出现的物体数量。

最后，本文每个任务随机采样了100张图片，并让3个人评估场景准确率。结果显示平均准确率为91.0%。

#### 问题分配

当模型被应用于一个新场景时，会面临两种问题：

1. 问题与场景中的一个独特物体有关，需要模型预测这个物体的名称作为一个场景独特的答案。

2. 问题涉及到普通的概念，需要模型预测常见的答案。

本文的场景增量设定包含着两种类型的问题。每个任务都有一些常见回答，也有一些其他任务没有的回答。对每个任务，本文收集相似数量的常见回答和独特回答。另外，本文会平衡不同任务之间的样本数量，并按照GQA的方法对任务之间答案分布进行平衡，防止数据集偏置。

![Fig3](./fig/CLOVE%20scene%20distribution.png)

![Fig4](./fig/CLOVE%20Scene%20Question%20Distribution.png)

### 功能设定

#### 样本分配

对物体识别、属性识别、关系推理和逻辑推理任务，本文从GQA数据集中搜集。对知识推理和场景文本理解任务，本文分别从CRIC和TextVQA数据集中进行搜集。对每一种任务，本文定义了对应的操作集。

![Fig2](./fig/CLOVE%20function%20operations.png)

#### 分布均衡

对于每个任务，本文尽可能将样本数量控制到差不多。

![Fig5](./fig/CLOVE%20function%20distribution.png)

![Fig6](./fig/CLOVE%20Function%20Question%20Distribution.png)

### SGP方法

传统的CL大致分为两种方法：

- 防止遗忘：传统的在图像分类上的VQA被设计用来防止遗忘视觉模态上的表示。但这对CLVQA不适用，因为VQA需要多模态的推理。

- 回放：一些其他工作通过回放来保留历史知识，但由于隐私的担忧，一般CL不会用真实的数据而是用伪数据。但是，在CLVQA上回放伪数据会非常有挑战性，因为VQA任务需要复杂的视觉场景和细粒度的内容，而SOTA图像GAN模型很难准确生成想要的图片。并且，低分辨率的图像质量也会对生成数据的质量有影响。

本文提出一个用于VQA中CL的基于回放的无真实数据的方法，用场景图谱作为提示来进行符号回放（SGP）。场景图谱是一个简洁、结构化的视觉信息表示，SGP通过使用场景图谱替代图像进行回放可以有效解决上述限制。

具体来说，SGP包括了一个符号回放模型（SRM）和一个统一VQA模型（UniVQA）。

- SRM是一个语言模型，会持续性捕捉符号推理机制并学习特定任务中场景图谱和问答对的映射。在推理阶段，SRM将<场景图谱、问题、答案>三元组进行知识回溯。

- UniVQA用来适应不同VQA任务的多种类型的输入模态。利用目前任务的样本、符号回放的样本进行训练，使得UniVQA可以在学习新任务的过程中保留先前需要的知识。

另外，由于之前的真实数据不被保存，本文的框架可被用于各种涉及隐私的应用。

## 实验

通过与不同现有的CL方法进行比较，本文展示了CLOVE的难度和SGP的有效性。
