# Dynamic Auxiliary Soft Labels for decoupled learning

## 背景

数据集分布不均是深度学习中最主要的挑战之一。CNN在小样本的情况下表现较差。

长尾分布：只有少部分类别占据着大多数数据，其他类别占据得很少。

下面是一些主流的解决长尾分布的方法：

- **重采样方法**：主要就是将尾类别过采样，将头类别下采样两种方法。
- **基于代价灵敏的方法**：计算损失函数的时候，将更多的损失倾向于尾类别。
- **分隔学习**，一种将特征学习阶段和分类器学习阶段分开学习的方法，能有效提升网络的表现能力。
- **基于迁移学习的方法**：将从头类别学到的知识迁移到学习尾类别中。
- **软标签方法**：通过生成软标签进行训练，来提高模型的泛化能力。

Label Smoothing方法效果反而恶化，原因可能是在生成软标签的时候，偏差会倾向于大比例标签。Online Label Smoothing方法，在特征学习阶段中的预测是存在偏差的，但是分类器学习阶段中的表示是固定不变的。

## DaSL

研究显示，如果特征学习阶段和分类器学习阶段分离开，那么模型准确率会得到很大的提升。硬标签中，类别概率非0即1，只有正确的类别概率才为1。而软标签的概率如下所示：

$$
\begin{aligned}
q_i^j = \begin{cases}
1 - \varepsilon & \text{if}\ j=k\\
\varepsilon / (K - 1) & \text{otherwise}.
\end{cases}
\end{aligned}
$$

本文设计一个专用的辅助网络来为两个学习阶段生成软标签。在特征学习阶段，软标签可以让网络学习到类之间的差异。在分类器学习阶段，软标签可以减轻模型预测的过度自信。

同时，本文在特征学习中引入一个特征层面提取方法，并通过多尺度特征融合提升大致特征。
