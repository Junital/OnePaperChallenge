# Embodied Task Planning with Large Language Models

## 背景

本文提出一个任务规划智能体，用于处理有物理场景限制的基本规划任务。通过将视觉感知模型和LLM相结合，智能体可以根据场景中存在的物体生成可执行的任务。具体来说，本文首先构建了一个多模态数据集，包括了室内场景、指令、行动规划三元组（GPT3.5生成的），并且更聚焦于长尾任务。然后通过微调预训练的LLM进行处理。
