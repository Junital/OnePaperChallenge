# 小样本困境下的深度学习图像识别综述

## 背景

深度学习方法极大依赖于大规模标注数据，而这极大限制并影响了其在广大领域的应用。首先，标注数据涉及到隐私问题；其次，也涉及到人力物力的耗费问题；最后，算力上也对硬件设备要求高。

### 小样本学习

目前经常研究的问题为N-way K-shot形式，即问题包括N种数据，每种数据只包含K个标注样本。

## 主流方法

### 数据增强

通过算法生成人工标注数据，扩充原有的数据量。其中，一种方法是用生成的伪数据来补充小样本数据；另一种方法是用伪数据锐化分类算法学习到的决策边界。

#### 伪数据补充

这种方法并不能有效帮助模型识别类内差异，非常依赖于原有数据集。

- **delta-encoder**：自编码器结构，将标注充分的数据进行学习，再将此信息应用辅助少量标注的数据上。
- **dual TriNet**：基于语义空间的数据增强，通过ResNet-18实现多级深度特征提取。并通过TriNet将特征映射到语义空间上；通过图片相似的语义上相近，将最相似的类别特征加入高斯噪声，输入人TriNet解码模块；输出的深度特征就可以用来进行数据增强。

![Fig1](./fig/Dual%20TriNet.png)

#### 伪数据锐化

将生成的伪数据锐化决策边界，提升分类技能。

**metaGAN**：通过将GAN生成的伪数据作为一个新类别（fake class）以此来改善决策边界。

![Fig2](./fig/metaGAN.png)

优势：算法简单，对生成器的训练要求低。

### 迁移学习

### 元学习
