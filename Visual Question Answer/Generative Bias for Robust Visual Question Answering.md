# Generative Bias for Robust Visual Question Answering

## 简介

VQA会受到数据集分布bias的影响，导致那些数据集比例大的答案更有可能作为答案的预测结果。本文基于生成式模型，利用对抗目标和知识蒸馏对模型进行偏置调整。

## 背景

目前，非常多的研究显示VQA在数据集之间存在偏置的倾向。并且VQA非常依赖于数据集之间的语言偏置。这样会导致模型倾向于只根据问题而不是图片预测相似的回答。

针对这个问题，最近的工作利用联邦学习（集成学习）来消除这一偏置。模型会同时学习到每一个数据集或模态的偏置。比方说，在一些研究中，可以利用QA通过模型回答问题给出的答案分布和问题的相关程度来决定语言先前偏置。之后，就用这个QA模型来训练一个鲁棒性高的VQA模型。如果QA模型表示先前偏置越好，那么就越可以避免VQA预测答案出现偏置的现象。

现有的基于联邦学习的方法不是用训练集进行预计算和统计，就是只计算单模态与答案之间的偏置。

本文推测目前现有的方法会出现偏置表示的限制，因为模型的表示容量会受到输入的限制。另外，预计算只能表示部分偏置，因为研究显示QA模型的标签分布和VQA模型的标签分布有显著不同。

![Fig1](./fig/VQA%20bias.png)

## GenB

因此，本文提出一种新颖的、随机的偏置模型来直接从VQA模型中学习到偏置。具体而言，本文将生成式对抗模型（GAN）作为偏置模型，通过引入一个随机的噪声向量，根据给定的问题模仿VQA模型的答案分布。

## 实验结果

## 个人感想
