# BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions

## 简介

本文侧重于无限制VQA任务上，目前的视觉语言模型不能将图片和文本很好地融合在一起。因为一般情况下都是将图片上的信息转化成文本，再作为prompt插入到问题中。并且，面对信息非常多的图片，输入token的限制也会导致不能很好回答。本文基于InstructBLIP设计了一个解决方案。
