# Region-aware Knowledge Distillation for Efficient Image-to-Image Translation

## 背景

图像对图像翻译任务中，GAN取得了很大的进展。但是，GAN经常会包含很多参数，导致了不可承受的内存和计算消耗，使其不能在终端设备上部署。为了解决这个问题，知识蒸馏可以将笨重的大模型中的知识迁移到有效的小模型上。但是大多数之前的知识蒸馏方法都是为图像分类设计的，对图像-图像翻译任务效果不是很好。本文提出区域级知识蒸馏，来压缩图像-图像翻译模型。首先，Reko会利用attention模块找到图片中最关键的区域。其次，使用patch级对抗学习最大化大小模型在这些关键区域的相互信息。最后的结果不仅仅压缩了、加速了而且还表现得更好。
