# G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering

## 背景

**图+LLM**：LLM的到来极大程度改变了人工智能的格局。由于被用于越来越多不同的任务，LLM需要具备处理复杂结构化的数据。尤其在目前这个相互联系的世界，真实世界数据往往以图谱的方式呈现，比如互联网、电商、推荐系统、知识图谱和其他数据。另外，许多数据涉及到带有文本属性的图谱，适合于以LLM为中心的方法。这促进了将基于图谱的方法（比如GNN）和LLM相结合促进图谱上的推理。

**赋能图谱聊天**：目前的方法以多种方式将GNN与LLM进行结合，大多关注于类似结点、边和图谱分类的传统图谱任务，或者根据小/合成的图谱回答简单问题。但是目前还没有面向真实世界、具备强大推理能力的方法。

**图谱问答任务难度需要提升**：问答是一个在自然语言处理中非常重要的任务，是评估LLM的一个关键benchmark、为不同的能力提供一个统一的接口。尽管在QA方面有广泛的研究，专门关注于图谱模态的研究还是挺少的。目前的benchmark关注于基本的基于图谱的推理任务，比如结点度数、边是否存在、最短路，与复杂、真实世界图谱涉及到的常识推理、场景理解和知识图谱推理距离还很远。

## G-Retriever

### 前置知识

**文本图谱**：文本图谱是结点和边都具备文本属性的图谱，可被定义为$G=(V, E, \{x_n\}_{n \in V}, \{x_e\}_{e \in E})$，其中$V$和$E$分别代表了结点和边。另外，$x_n \in D^{L_n}$和$x_e \in D^{L_e}$表示着与结点$n \in V$或者边$e \in E$相联系的序列文本，其中$D$代表着字典，$L_n$和$L_e$表示对应序列文本的长度。

**文本编码的语言模型**：在文本图谱的场景下，语言模型（LM）对与结点和边关联的文本编码至关重要。因此语言模型需要通过学习表示来捕捉语义含义。对于带有文本属性$x_n \in D^{L_n}$的结点$n$，语言模型将这些属性编码为：

$$z_n = \text{LM}(x_n) \in \mathbb{R}^d$$

其中，$z_n$是LM的输出、$d$是输出向量的维度。

**大预言模型与提示微调**：LLM为任务适配引入了一个新范式：“预训练，提示词，预测”，将微调换为了提示微调。在这个范式中，LLM会首先在巨大的语料库中学习一般的语言表示。之后，不用特定任务的数据微调模型，只讲制作一个上下文和任务的文本提示词。随后，模型直接基于提示词和输入生成输出。

配备权重$\theta$的LLM，将token序列$X$和提示词$P$作为输入，生成token序列$Y = \{y_1, y_2, \cdots, y_r\}$作为输出。

本文设置了一个面向真实世界文本图谱的问答框架，能处理场景图谱理解、常识推理和知识图谱推理，赋能图谱聊天。

![Fig1](./fig/Real-world%20Graph%20QA.png)

为了实现这个目标，本文首先通过不同任务中收集到的数据开发了图谱问答（GraphQA）benchmark。

![Fig2](./fig/GraphQA.png)

之后，为了促进有效且高效的图谱问答，本文提出了G-Retriever方法，综合使用GNN、LLM、RAG的优势，这是首个对一般文本图谱进行的提取增强生成（RAG）方法，通过软提示来增强图谱理解的能力。为了避免幻觉现象同时解决图谱长度超过LLM上下文限制的情况，G-Retriever通过将任务视为奖品收集斯坦纳树优化问题，对图谱进行RAG操作。

![Fig3](./fig/G-Retriever.png)

**图谱LLM中的幻觉现象**：为了调查图谱LLM中的幻觉现象，本文验证了其在图谱场景下是否会出现。具体来说，本文将MiniGPT-4适应于图谱，构建一个baseline方法，其中GNN是可训练的，将图谱数据进行编码作为LLM的软提示，LLM是冻结的。通过实验，本文发现在图谱LLM中幻觉现象也很常见。这主要是因为baseline不具备从一个单一的图谱嵌入中学习整个图谱结构的能力，从而在问答任务中生成了错误的结点或边。相反，通过将RAG引用于直接信息提取上，本文的G-Retriever减轻了这一问题。

![Fig4](./fig/graph%20LLM%20hallucination.png)

**提升图谱LLM的可拓展性和有效性**：目前很多工作致力于将图谱翻译为自然语言，比如将结点和边合并为一个文本序列，使LLM能够处理图谱任务。但是，这种方法不具备可拓展性，如果将包含上千个结点和边的图转化为文本序列会导致庞大的token数量，这不是大多数LLM能接受的。但如果简单的截取文本长度会导致信息和回答质量的损失。G-Retriever的优势在于，选择性地将图谱相关部分进行提取。

**为图谱挑选适合的RAG方法**：目前RAG方法主要视为更加简单的数据类型或知识图谱类型设计的，这种类型于图结构有所区别。因此，本文为一般文本图谱引入了一个新的提取方法。具体来说，本文将子图提取视为奖品收集斯坦纳树优化问题，在提取过程中将邻居的信息考虑进去。这样将最相关的子图进行询问，促进了图谱LLM的可解释性。

## 实验结果

实验结果表现很好。
