# Active Inference in Robotics and Artificial Agents: Survey and Challenges

## 背景

实时推理是一个源于神经学关于大脑响应、感知和学习理论知识的数学框架。

理论部分很多都是马尔可夫等数学公式，感兴趣可以之后细读。

## 机器人实验

### 适应控制

实时推理控制器（AIC）在适应未建模状态、调整能耗、干扰对抗、计算能耗和抓放任务整体表现超过了模型参考适应控制（MRAC）。一个AIC比较大的优势在于，不需要重新调整就可以实现从机器人模拟到实际机器人的迁移。

多感知AIF相比优化控制器更能适应外在和内在的参数变化，比如重力、硬度、末端惯性、外在扰动。自动调整的方法会比人工调整AIC在响应和鲁棒性方面有提升。

### 容忍错误控制

### 规划

带有奖励机制的AIF V.S. 强化学习SAC

![Fig1](./Fig/AIF%20planing%20reward.png)

### 复杂认知

- 意图混合人机协作

## 与其他框架的联系

### 和经典控制器的关系

### 和强化学习的关系

RL和AIF规划的区别在于：RL没有考虑期望自由能量的内在和后来的差异。

## AIF的利弊风险

### 未拟合的框架

1. 如何避免次优的收敛。
2. 活动中是否由一些连续时间反馈信号组成。

### 功能性生物可解释性

### 多变的贝叶斯推理

## 个人感想

介绍了除人工智能外，能用纯数学的方式对机器人进行推理。如果之后对强化学习有研究，也可以从这个方向上突破。
