# RelTR: Relation Transformer for Scene Graph Generation

## 背景

在相同场景下的不同物体或多或少都会相互关联，但是只有一定数量的关系是值得关注的。受到在物体检测任务中表现出色的Detection Transformer的启发，本文将场景图谱生成视为一个集合预测问题。本文将提出一个端到端场景图谱生成模型Relation Transformer（RelTR），包含了一个encoder-decoder架构。encoder将对视觉特征进行推理，而decoder将用带有主体-客体对的请求的不同类型的注意力机制推理一个固定大小的主谓宾三元组集合。本文为端到端训练设计了一组预测损失，对真实场景图谱和预测场景图谱进行匹配。相比于大多数现存的场景图谱生成方法，RelTR是一个仅仅使用视觉纹理、不结合实体、不对所有可能的谓语打上标签，直接预测稀疏场景图谱单阶段方法。
