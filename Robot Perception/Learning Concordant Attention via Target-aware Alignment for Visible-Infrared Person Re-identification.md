# Learning Concordant Attention via Target-aware Alignment for Visible-Infrared Person Re-identification

## 背景

行人重识别（Re-ID）通过不重叠的相机来联系行人实体。目前这在真实监控系统的应用上有广泛关注。

传统的方法主要侧重于对不同的相机提取相同的实体。尽管这种方法取得了显著的成功，但是受到了弱光条件（夜晚）的限制。未来提升光照的限制，红外相机将与可见光照相机一起在真实监控系统中使用。而任务就变为了：可见光-红外线跨模态行人重识别（VI Re-ID），在不同光谱下拍摄行人照片来进行长期行人跟踪。

与传统彩色照片重识别不同，VI Re-ID会因为彩色和红外图像之间的差距增加识别的难度。由于VI Re-ID各种数据之间存在巨大的分布差距，本文指出目前的范式经常会出现模态间语义对不齐的现象，因此无法准确对齐、比较局部细节。除此之外，VI Re-ID和Re-ID一样也会受到姿势、环境改变的影响。

目前大多数的方法只考虑了整个图像的全局表示，而没有比对图像的局部细节。除此之外，一种看似直接的方法就是用分离技术、辅助模型技术或者注意力技术来学习语义对齐局部特征。但是，这些方法无法取得模态间的语义对齐。如果强制将这些对不齐的语义嵌入对齐会对训练过程造成破坏，降低最终表现。

![Fig1](./Fig/VI%20Re-ID%20paradigm.png)

与这些深度学习方法不同，人类视觉系统由于有目标级比对策略，能很自然避免无法对齐的问题。考虑到比较两张行人照片的场景，人类视觉系统会首先在目标图像上识别多个不同的关键区域，并与主图像中的对应区域进行比对。在这种方法下，人类可以一直进行部分之间的比对直到找到了合适的匹配。这个思路说明从找到目标图像上的模态对应部分和有效的跨模态对应区域搜索策略能解决模态间的语义不对齐问题。

## CAL

本文提出协调注意力学习（CAL），一种为VI Re-ID学习语义对齐表示的新框架。

具体来说，本文设计一个目标级协调对齐（TCA）范式，在对齐各种样本的时候允许目标级注意力适应。其中包括三个部分：

- 显著区域挖掘：从每个训练样本的特征映射中识别不同的、显著的关键区域。
- 目标级样式诊断特征适应器：将从目标模态中提取的关键区域作为query，使用目标级改良来适应特征注意力、生成部分对齐的嵌入。
- 部分对齐度量学习：根据实体标签对跨模态的部分对齐的嵌入进行聚类和分割。

尽管目标级改良方案可以通过使用目标模态上的线索来缓解模态的差异，但它在推理中带来更高的计算成本。因为它需要为所有query-gallery配对都执行一次，而gallery库中的样本很多。

因此，本文进一步提出MatchDistill。首先，本文需要将不同模态生成的部分query进行联系，从而保证随后的提取会在语义对齐的特征上进行。这可以通过用双向图谱建模对应的注意力映射，并使用跨模态query匹配（CQM）来寻找优化配对。之后，本文设计一个二元级知识提取损失，从而进行最佳匹配query之间的跨模态知识交换。这可以促进学习可见光和红外线模态之间的潜在关系。

训练MatchDistill之后，每个模态可以从另一模态学到知识，并且在推理阶段不需要跨模态的交互。

## 实验

实验展示出CAL的有效性和优越性。
