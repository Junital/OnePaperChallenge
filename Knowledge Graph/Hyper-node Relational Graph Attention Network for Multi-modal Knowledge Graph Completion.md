# Hyper-node Relational Graph Attention Network for Multi-modal Knowledge Graph Completion

## 背景

知识图谱经常遭遇不完备的困境。知识图谱补全就是用来从知识图谱确定的事实三元组中，推断出缺失的三元组。但是，大多数方法只适用知识图谱的相关信息，将实体和关系作为带有简单嵌入层的ID，忽视了三元组之间的多模态信息，比如文本表述、图片等。本文提出了一中新颖的网络，将不同的模态信息和图谱结构信息进行合并，来获得更多准确的多模态知识图谱表示，称之为超结点关联图谱注意力网络（HRGAT）。本文使用了低秩多模态融合来构建模态内和模态间相互作用模型，这将原来的图纸图谱变成了一个超结点图谱。之后，包含特定关联注意力和实体关联融合操作的RGAT被用来捕捉图谱结构的信息。最后，本文统计了更新的多模态信息和图结构信息来生成最后知识图谱的嵌入，从而进行知识图谱补全。
