# KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning

## 背景

大语言模型通过思维链进行逐步思考，在自然语言处理任务中展现出了出色的表现。将大语言模型拓展多模态能力是最近的热门，但是这种拓展招致了计算开销，需要庞大的硬件资源。为了解决这些挑战，本文提出了KAM-CoT，通过使用思维链推理、知识图谱和多模态进行复杂理解的框架。KAM-CoT采用了一个双阶段训练过程，利用只是图谱来生成有效的推理和答案。通过在推理中能从知识图谱中获得额外的知识，模型得到了更深的上下文理解力、减少幻觉现象并提升回答质量。这一知识增强的思维链推理促使模型能解决需要额外上下文的问题，从而提供了更多信息。实验显示模型的效果超过了SOTA方法，并且只需要280M可训练参数，实现了轻量化和有效性。
